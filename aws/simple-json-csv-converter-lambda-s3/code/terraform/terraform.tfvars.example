# =============================================================================
# TERRAFORM VARIABLES EXAMPLE
# =============================================================================
# This file provides example values for customizing the JSON-to-CSV converter
# deployment. Copy this file to terraform.tfvars and modify the values to
# match your requirements.
#
# Usage:
#   cp terraform.tfvars.example terraform.tfvars
#   # Edit terraform.tfvars with your values
#   terraform plan
#   terraform apply
# =============================================================================

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================

# Prefixes for S3 bucket names (will be made unique with random suffix)
input_bucket_prefix  = "my-json-input"
output_bucket_prefix = "my-csv-output"

# Lambda function base name
lambda_function_name = "my-json-csv-converter"

# Environment designation
environment = "development"  # Options: development, staging, production

# =============================================================================
# LAMBDA FUNCTION SETTINGS
# =============================================================================

# Python runtime version for Lambda function
lambda_runtime = "python3.12"  # Options: python3.8, python3.9, python3.10, python3.11, python3.12

# Function timeout in seconds (max: 900 seconds = 15 minutes)
lambda_timeout = 60

# Memory allocation for Lambda function (128-10240 MB)
lambda_memory_size = 256

# Architecture type
lambda_architecture = "x86_64"  # Options: x86_64, arm64

# Reserved concurrency (0 = unreserved, -1 = disable function)
lambda_reserved_concurrency = 0

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================

# CloudWatch log retention period
log_retention_days = 30  # Options: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653

# Enable CloudWatch monitoring alarms
enable_monitoring = true

# SNS topic ARN for alarm notifications (leave empty to disable)
alarm_sns_topic_arn = ""
# alarm_sns_topic_arn = "arn:aws:sns:us-east-1:123456789012:alerts"

# Enable Lambda Insights for enhanced monitoring
enable_lambda_insights = false

# =============================================================================
# FILE PROCESSING CONFIGURATION
# =============================================================================

# Prefix filter for input files (empty for no filter)
input_file_prefix = ""
# input_file_prefix = "data/"  # Only process files starting with "data/"

# Supported file extensions
supported_file_extensions = [".json"]

# Maximum file size in MB
max_file_size_mb = 50

# Maximum concurrent Lambda executions
max_concurrent_executions = 10

# =============================================================================
# RESOURCE TAGGING
# =============================================================================

# Common tags applied to all resources
common_tags = {
  Project      = "DataProcessingPipeline"
  Environment  = "development"
  Owner        = "data-team"
  CostCenter   = "engineering"
  ManagedBy    = "terraform"
  Purpose      = "json-csv-conversion"
  Category     = "serverless"
  Department   = "analytics"
}

# Additional configuration
cost_center   = "data-analytics-team"
owner_email   = "data-team@company.com"

# =============================================================================
# REGIONAL CONFIGURATION
# =============================================================================

# AWS region (leave empty to use provider default)
aws_region = ""
# aws_region = "us-east-1"

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# S3 security settings (recommended to keep as true)
enable_s3_encryption        = true
enable_s3_versioning        = true
enable_public_access_block  = true

# =============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT ENVIRONMENTS
# =============================================================================

# Development Environment Example:
# environment = "development"
# lambda_memory_size = 256
# lambda_timeout = 60
# log_retention_days = 7
# enable_monitoring = false
# max_concurrent_executions = 5

# Production Environment Example:
# environment = "production"
# lambda_memory_size = 512
# lambda_timeout = 300
# log_retention_days = 90
# enable_monitoring = true
# enable_lambda_insights = true
# max_concurrent_executions = 50
# alarm_sns_topic_arn = "arn:aws:sns:us-east-1:123456789012:production-alerts"

# High-Volume Processing Example:
# lambda_memory_size = 1024
# lambda_timeout = 900
# max_concurrent_executions = 100
# lambda_reserved_concurrency = 50
# enable_lambda_insights = true

# Cost-Optimized Example:
# lambda_memory_size = 128
# lambda_timeout = 30
# log_retention_days = 3
# enable_monitoring = false
# max_concurrent_executions = 5
# lambda_architecture = "arm64"  # Graviton2 processors for better price-performance

# =============================================================================
# DEAD LETTER QUEUE CONFIGURATION (OPTIONAL)
# =============================================================================

# Uncomment to enable dead letter queue for failed executions
# lambda_dead_letter_config = {
#   target_arn = "arn:aws:sqs:us-east-1:123456789012:failed-conversions-dlq"
# }