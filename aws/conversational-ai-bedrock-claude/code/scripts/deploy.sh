#!/bin/bash
#
# Deployment script for Conversational AI Applications with Amazon Bedrock and Claude
# This script deploys the complete infrastructure including DynamoDB, Lambda, API Gateway, and IAM resources
#
# Usage: ./deploy.sh [--dry-run] [--skip-bedrock-check]
#
# Author: Generated by Claude Code Recipe System
# Version: 1.0
# Last Updated: 2025-07-12

set -euo pipefail

# Color codes for output formatting
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Script configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="${SCRIPT_DIR}/deploy.log"
DRY_RUN=false
SKIP_BEDROCK_CHECK=false

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --skip-bedrock-check)
            SKIP_BEDROCK_CHECK=true
            shift
            ;;
        -h|--help)
            echo "Usage: $0 [--dry-run] [--skip-bedrock-check]"
            echo "  --dry-run              Show what would be deployed without making changes"
            echo "  --skip-bedrock-check   Skip Bedrock model access verification"
            echo "  -h, --help             Show this help message"
            exit 0
            ;;
        *)
            echo "Unknown option $1"
            exit 1
            ;;
    esac
done

# Logging function
log() {
    local level=$1
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case $level in
        INFO)
            echo -e "${GREEN}[INFO]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        WARN)
            echo -e "${YELLOW}[WARN]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        ERROR)
            echo -e "${RED}[ERROR]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        DEBUG)
            echo -e "${BLUE}[DEBUG]${NC} $message" | tee -a "$LOG_FILE"
            ;;
    esac
    echo "[$timestamp] [$level] $message" >> "$LOG_FILE"
}

# Error handling function
handle_error() {
    local exit_code=$?
    local line_number=$1
    log ERROR "Script failed at line $line_number with exit code $exit_code"
    log ERROR "Check the log file at $LOG_FILE for details"
    exit $exit_code
}

trap 'handle_error $LINENO' ERR

# Initialize log file
echo "=== Conversational AI Deployment Started at $(date) ===" > "$LOG_FILE"

log INFO "Starting deployment of Conversational AI Applications with Amazon Bedrock and Claude"

# Prerequisite checks
check_prerequisites() {
    log INFO "Checking prerequisites..."
    
    # Check if AWS CLI is installed
    if ! command -v aws &> /dev/null; then
        log ERROR "AWS CLI is not installed. Please install AWS CLI v2 and configure it."
        exit 1
    fi
    
    # Check AWS CLI version
    local aws_version=$(aws --version 2>&1 | cut -d/ -f2 | cut -d' ' -f1)
    log INFO "AWS CLI version: $aws_version"
    
    # Check if user is authenticated
    if ! aws sts get-caller-identity &> /dev/null; then
        log ERROR "AWS credentials not configured. Please run 'aws configure' or set up appropriate credentials."
        exit 1
    fi
    
    # Get caller identity
    local caller_identity=$(aws sts get-caller-identity --output text)
    log INFO "Authenticated as: $caller_identity"
    
    # Check if Python 3 is available for test scripts
    if ! command -v python3 &> /dev/null; then
        log WARN "Python 3 not found. Test scripts may not work."
    fi
    
    # Check if pip3 is available
    if ! command -v pip3 &> /dev/null; then
        log WARN "pip3 not found. Installing test dependencies may fail."
    fi
    
    log INFO "Prerequisites check completed successfully"
}

# Set up environment variables
setup_environment() {
    log INFO "Setting up environment variables..."
    
    # Get AWS region and account ID
    export AWS_REGION=$(aws configure get region)
    if [[ -z "$AWS_REGION" ]]; then
        log ERROR "AWS region not configured. Please set a default region."
        exit 1
    fi
    
    export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    
    # Generate unique identifiers to avoid naming conflicts
    RANDOM_SUFFIX=$(aws secretsmanager get-random-password \
        --exclude-punctuation --exclude-uppercase \
        --password-length 6 --require-each-included-type \
        --output text --query RandomPassword)
    
    export TABLE_NAME="conversational-ai-${RANDOM_SUFFIX}"
    export API_NAME="conversational-ai-api-${RANDOM_SUFFIX}"
    export LAMBDA_FUNCTION_NAME="conversational-ai-handler-${RANDOM_SUFFIX}"
    export IAM_ROLE_NAME="ConversationalAILambdaRole-${RANDOM_SUFFIX}"
    
    log INFO "Environment configured:"
    log INFO "  AWS Region: $AWS_REGION"
    log INFO "  AWS Account: $AWS_ACCOUNT_ID"
    log INFO "  Table Name: $TABLE_NAME"
    log INFO "  API Name: $API_NAME"
    log INFO "  Lambda Function: $LAMBDA_FUNCTION_NAME"
    log INFO "  IAM Role: $IAM_ROLE_NAME"
    
    # Save environment variables to file for cleanup script
    cat > "${SCRIPT_DIR}/.env" << EOF
AWS_REGION=$AWS_REGION
AWS_ACCOUNT_ID=$AWS_ACCOUNT_ID
TABLE_NAME=$TABLE_NAME
API_NAME=$API_NAME
LAMBDA_FUNCTION_NAME=$LAMBDA_FUNCTION_NAME
IAM_ROLE_NAME=$IAM_ROLE_NAME
RANDOM_SUFFIX=$RANDOM_SUFFIX
EOF
    
    log INFO "Environment variables saved to ${SCRIPT_DIR}/.env"
}

# Check Bedrock model access
check_bedrock_access() {
    if [[ "$SKIP_BEDROCK_CHECK" == "true" ]]; then
        log WARN "Skipping Bedrock model access check as requested"
        export CLAUDE_MODEL_ID="anthropic.claude-3-haiku-20240307-v1:0"
        return
    fi
    
    log INFO "Checking Bedrock model access..."
    
    # Check if Bedrock service is available in the region
    if ! aws bedrock list-foundation-models &> /dev/null; then
        log ERROR "Bedrock service not available in region $AWS_REGION or insufficient permissions"
        log ERROR "Please check: 1) Bedrock is available in your region, 2) You have Bedrock permissions"
        exit 1
    fi
    
    # List available Claude models
    local claude_models=$(aws bedrock list-foundation-models \
        --query 'modelSummaries[?contains(modelId, `claude-3`)].modelId' \
        --output text 2>/dev/null || echo "")
    
    if [[ -z "$claude_models" ]]; then
        log ERROR "No Claude models available. Please request access through AWS Console:"
        log ERROR "1. Go to AWS Console > Amazon Bedrock > Model access"
        log ERROR "2. Request access to Claude models (Claude 3 Haiku, Sonnet, or Opus)"
        log ERROR "3. Wait for approval (usually takes a few minutes)"
        log ERROR "4. Re-run this script"
        exit 1
    fi
    
    # Use the first available Claude model
    export CLAUDE_MODEL_ID=$(echo $claude_models | awk '{print $1}')
    log INFO "Using Claude model: $CLAUDE_MODEL_ID"
    
    # Test model access by attempting to list models
    if ! aws bedrock list-foundation-models --query "modelSummaries[?modelId=='$CLAUDE_MODEL_ID']" &> /dev/null; then
        log ERROR "Cannot access Claude model $CLAUDE_MODEL_ID. Please check permissions."
        exit 1
    fi
    
    log INFO "Bedrock model access verified successfully"
}

# Create DynamoDB table
create_dynamodb_table() {
    log INFO "Creating DynamoDB table for conversation storage..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log INFO "[DRY RUN] Would create DynamoDB table: $TABLE_NAME"
        return
    fi
    
    # Check if table already exists
    if aws dynamodb describe-table --table-name "$TABLE_NAME" &> /dev/null; then
        log WARN "DynamoDB table $TABLE_NAME already exists, skipping creation"
        return
    fi
    
    aws dynamodb create-table \
        --table-name "$TABLE_NAME" \
        --attribute-definitions \
            AttributeName=session_id,AttributeType=S \
            AttributeName=timestamp,AttributeType=N \
        --key-schema \
            AttributeName=session_id,KeyType=HASH \
            AttributeName=timestamp,KeyType=RANGE \
        --billing-mode PAY_PER_REQUEST \
        --stream-specification StreamEnabled=false \
        --tags Key=Project,Value=ConversationalAI Key=CreatedBy,Value=DeployScript
    
    log INFO "Waiting for DynamoDB table to be ready..."
    aws dynamodb wait table-exists --table-name "$TABLE_NAME"
    
    log INFO "DynamoDB table created successfully: $TABLE_NAME"
}

# Create IAM role for Lambda
create_iam_role() {
    log INFO "Creating IAM role for Lambda functions..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log INFO "[DRY RUN] Would create IAM role: $IAM_ROLE_NAME"
        return
    fi
    
    # Check if role already exists
    if aws iam get-role --role-name "$IAM_ROLE_NAME" &> /dev/null; then
        log WARN "IAM role $IAM_ROLE_NAME already exists, skipping creation"
        export LAMBDA_ROLE_ARN=$(aws iam get-role --role-name "$IAM_ROLE_NAME" --query 'Role.Arn' --output text)
        return
    fi
    
    # Create trust policy
    local trust_policy=$(cat << 'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF
)
    
    # Create IAM role
    aws iam create-role \
        --role-name "$IAM_ROLE_NAME" \
        --assume-role-policy-document "$trust_policy" \
        --tags Key=Project,Value=ConversationalAI Key=CreatedBy,Value=DeployScript
    
    # Create custom policy
    local custom_policy=$(cat << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel",
        "bedrock:InvokeModelWithResponseStream"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:Query",
        "dynamodb:UpdateItem",
        "dynamodb:DeleteItem"
      ],
      "Resource": "arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/${TABLE_NAME}"
    },
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "xray:PutTraceSegments",
        "xray:PutTelemetryRecords"
      ],
      "Resource": "*"
    }
  ]
}
EOF
)
    
    # Attach custom policy
    aws iam put-role-policy \
        --role-name "$IAM_ROLE_NAME" \
        --policy-name BedrockDynamoDBPolicy \
        --policy-document "$custom_policy"
    
    # Attach managed policy
    aws iam attach-role-policy \
        --role-name "$IAM_ROLE_NAME" \
        --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
    
    # Get role ARN
    export LAMBDA_ROLE_ARN=$(aws iam get-role --role-name "$IAM_ROLE_NAME" --query 'Role.Arn' --output text)
    
    log INFO "IAM role created successfully: $LAMBDA_ROLE_ARN"
    
    # Wait for role to be available (eventual consistency)
    log INFO "Waiting for IAM role to be available..."
    sleep 10
}

# Create Lambda function
create_lambda_function() {
    log INFO "Creating Lambda function for conversational AI..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log INFO "[DRY RUN] Would create Lambda function: $LAMBDA_FUNCTION_NAME"
        return
    fi
    
    # Check if function already exists
    if aws lambda get-function --function-name "$LAMBDA_FUNCTION_NAME" &> /dev/null; then
        log WARN "Lambda function $LAMBDA_FUNCTION_NAME already exists, updating code..."
    fi
    
    # Create Lambda function code
    local function_code="${SCRIPT_DIR}/conversational_ai_handler.py"
    cat > "$function_code" << EOF
import json
import boto3
import uuid
import time
from datetime import datetime
import logging

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize AWS clients
bedrock_runtime = boto3.client('bedrock-runtime')
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('${TABLE_NAME}')

# Claude model configuration
CLAUDE_MODEL_ID = '${CLAUDE_MODEL_ID}'
MAX_TOKENS = 1000
TEMPERATURE = 0.7

def lambda_handler(event, context):
    """Main handler for conversational AI requests"""
    
    try:
        # Parse request body from API Gateway
        body = json.loads(event.get('body', '{}'))
        user_message = body.get('message', '')
        session_id = body.get('session_id', str(uuid.uuid4()))
        user_id = body.get('user_id', 'anonymous')
        
        if not user_message:
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json'},
                'body': json.dumps({'error': 'Message is required'})
            }
        
        # Get conversation history for context
        conversation_history = get_conversation_history(session_id)
        
        # Build prompt with conversation context
        prompt = build_prompt_with_context(user_message, conversation_history)
        
        # Call Bedrock Claude model for AI response
        response = invoke_claude_model(prompt)
        
        # Save this conversation turn to DynamoDB
        save_conversation_turn(session_id, user_id, user_message, response)
        
        # Return successful response
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type'
            },
            'body': json.dumps({
                'response': response,
                'session_id': session_id,
                'timestamp': datetime.utcnow().isoformat()
            })
        }
        
    except Exception as e:
        logger.error(f"Error processing request: {str(e)}")
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'Internal server error'})
        }

def get_conversation_history(session_id, limit=10):
    """Retrieve recent conversation history for context"""
    
    try:
        response = table.query(
            KeyConditionExpression='session_id = :session_id',
            ExpressionAttributeValues={':session_id': session_id},
            ScanIndexForward=False,  # Most recent first
            Limit=limit * 2  # Get both user and assistant messages
        )
        
        # Format conversation history
        history = []
        for item in reversed(response['Items']):
            history.append({
                'role': item['role'],
                'content': item['content']
            })
        
        return history[-limit:] if len(history) > limit else history
        
    except Exception as e:
        logger.error(f"Error retrieving conversation history: {str(e)}")
        return []

def build_prompt_with_context(user_message, conversation_history):
    """Build Claude prompt with conversation context"""
    
    # System prompt defines the AI's behavior and personality
    system_prompt = """You are a helpful AI assistant. You provide accurate, helpful, and engaging responses to user questions. You maintain context from previous messages in the conversation and provide personalized assistance."""
    
    # Build conversation context
    messages = [{"role": "system", "content": system_prompt}]
    
    # Add conversation history for context
    for turn in conversation_history:
        messages.append({
            "role": turn['role'],
            "content": turn['content']
        })
    
    # Add current user message
    messages.append({
        "role": "user",
        "content": user_message
    })
    
    return messages

def invoke_claude_model(messages):
    """Invoke Claude model through Bedrock"""
    
    try:
        # Prepare request body for Claude API format
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": MAX_TOKENS,
            "temperature": TEMPERATURE,
            "messages": messages[1:]  # Exclude system message for Claude format
        }
        
        # Add system message if present
        if messages[0]["role"] == "system":
            request_body["system"] = messages[0]["content"]
        
        # Invoke model through Bedrock Runtime
        response = bedrock_runtime.invoke_model(
            modelId=CLAUDE_MODEL_ID,
            body=json.dumps(request_body),
            contentType='application/json'
        )
        
        # Parse response
        response_body = json.loads(response['body'].read())
        
        # Extract text from Claude response
        if 'content' in response_body and len(response_body['content']) > 0:
            return response_body['content'][0]['text']
        else:
            return "I apologize, but I couldn't generate a response. Please try again."
            
    except Exception as e:
        logger.error(f"Error invoking Claude model: {str(e)}")
        return "I'm experiencing technical difficulties. Please try again later."

def save_conversation_turn(session_id, user_id, user_message, assistant_response):
    """Save conversation turn to DynamoDB"""
    
    try:
        timestamp = int(time.time() * 1000)  # Milliseconds for better sorting
        
        # Save user message
        table.put_item(
            Item={
                'session_id': session_id,
                'timestamp': timestamp,
                'role': 'user',
                'content': user_message,
                'user_id': user_id,
                'created_at': datetime.utcnow().isoformat()
            }
        )
        
        # Save assistant response
        table.put_item(
            Item={
                'session_id': session_id,
                'timestamp': timestamp + 1,  # Ensure assistant response comes after user message
                'role': 'assistant',
                'content': assistant_response,
                'user_id': user_id,
                'created_at': datetime.utcnow().isoformat()
            }
        )
        
        logger.info(f"Saved conversation turn for session {session_id}")
        
    except Exception as e:
        logger.error(f"Error saving conversation: {str(e)}")
EOF
    
    # Create deployment package
    local zip_file="${SCRIPT_DIR}/conversational_ai_handler.zip"
    (cd "$(dirname "$function_code")" && zip -q "$zip_file" "$(basename "$function_code")")
    
    # Create or update Lambda function
    if aws lambda get-function --function-name "$LAMBDA_FUNCTION_NAME" &> /dev/null; then
        aws lambda update-function-code \
            --function-name "$LAMBDA_FUNCTION_NAME" \
            --zip-file "fileb://$zip_file"
        
        aws lambda update-function-configuration \
            --function-name "$LAMBDA_FUNCTION_NAME" \
            --environment "Variables={TABLE_NAME=$TABLE_NAME,CLAUDE_MODEL_ID=$CLAUDE_MODEL_ID}" \
            --timeout 30 \
            --memory-size 512 \
            --tracing-config Mode=Active
    else
        aws lambda create-function \
            --function-name "$LAMBDA_FUNCTION_NAME" \
            --runtime python3.9 \
            --role "$LAMBDA_ROLE_ARN" \
            --handler conversational_ai_handler.lambda_handler \
            --zip-file "fileb://$zip_file" \
            --timeout 30 \
            --memory-size 512 \
            --environment "Variables={TABLE_NAME=$TABLE_NAME,CLAUDE_MODEL_ID=$CLAUDE_MODEL_ID}" \
            --tracing-config Mode=Active \
            --tags Project=ConversationalAI,CreatedBy=DeployScript
    fi
    
    # Get function ARN
    export LAMBDA_FUNCTION_ARN=$(aws lambda get-function \
        --function-name "$LAMBDA_FUNCTION_NAME" \
        --query 'Configuration.FunctionArn' --output text)
    
    log INFO "Lambda function created/updated successfully: $LAMBDA_FUNCTION_ARN"
    
    # Clean up temporary files
    rm -f "$function_code" "$zip_file"
}

# Create API Gateway
create_api_gateway() {
    log INFO "Creating API Gateway for REST API access..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log INFO "[DRY RUN] Would create API Gateway: $API_NAME"
        return
    fi
    
    # Check if API already exists
    local existing_api=$(aws apigateway get-rest-apis \
        --query "items[?name=='$API_NAME'].id" --output text 2>/dev/null || echo "")
    
    if [[ -n "$existing_api" ]]; then
        log WARN "API Gateway $API_NAME already exists, using existing API"
        export API_ID="$existing_api"
    else
        # Create REST API
        export API_ID=$(aws apigateway create-rest-api \
            --name "$API_NAME" \
            --description "Conversational AI API using Bedrock Claude" \
            --endpoint-configuration types=REGIONAL \
            --query 'id' --output text)
        
        log INFO "Created API Gateway: $API_ID"
    fi
    
    # Get root resource ID
    local root_resource_id=$(aws apigateway get-resources \
        --rest-api-id "$API_ID" \
        --query 'items[0].id' --output text)
    
    # Create /chat resource
    local chat_resource_id=$(aws apigateway create-resource \
        --rest-api-id "$API_ID" \
        --parent-id "$root_resource_id" \
        --path-part chat \
        --query 'id' --output text 2>/dev/null || \
        aws apigateway get-resources \
            --rest-api-id "$API_ID" \
            --query "items[?pathPart=='chat'].id" --output text)
    
    # Create POST method
    aws apigateway put-method \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method POST \
        --authorization-type NONE 2>/dev/null || true
    
    # Create OPTIONS method for CORS
    aws apigateway put-method \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method OPTIONS \
        --authorization-type NONE 2>/dev/null || true
    
    # Set up Lambda integration
    aws apigateway put-integration \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method POST \
        --type AWS_PROXY \
        --integration-http-method POST \
        --uri "arn:aws:apigateway:$AWS_REGION:lambda:path/2015-03-31/functions/$LAMBDA_FUNCTION_ARN/invocations" 2>/dev/null || true
    
    # Set up CORS integration
    aws apigateway put-integration \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method OPTIONS \
        --type MOCK \
        --request-templates '{"application/json": "{\"statusCode\":200}"}' 2>/dev/null || true
    
    # Configure method responses
    aws apigateway put-method-response \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method POST \
        --status-code 200 2>/dev/null || true
    
    aws apigateway put-method-response \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method OPTIONS \
        --status-code 200 \
        --response-parameters '{
          "method.response.header.Access-Control-Allow-Origin":false,
          "method.response.header.Access-Control-Allow-Methods": false,
          "method.response.header.Access-Control-Allow-Headers": false
        }' 2>/dev/null || true
    
    # Set up integration responses
    aws apigateway put-integration-response \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method POST \
        --status-code 200 2>/dev/null || true
    
    aws apigateway put-integration-response \
        --rest-api-id "$API_ID" \
        --resource-id "$chat_resource_id" \
        --http-method OPTIONS \
        --status-code 200 \
        --response-parameters '{
          "method.response.header.Access-Control-Allow-Origin": "'"'"'*'"'"'",
          "method.response.header.Access-Control-Allow-Methods": "'"'"'POST,OPTIONS'"'"'",
          "method.response.header.Access-Control-Allow-Headers": "'"'"'Content-Type'"'"'"
        }' 2>/dev/null || true
    
    # Grant API Gateway permission to invoke Lambda
    aws lambda add-permission \
        --function-name "$LAMBDA_FUNCTION_NAME" \
        --statement-id apigateway-invoke-"$(date +%s)" \
        --action lambda:InvokeFunction \
        --principal apigateway.amazonaws.com \
        --source-arn "arn:aws:execute-api:$AWS_REGION:$AWS_ACCOUNT_ID:$API_ID/*/*" 2>/dev/null || true
    
    # Deploy the API
    aws apigateway create-deployment \
        --rest-api-id "$API_ID" \
        --stage-name prod \
        --stage-description "Production stage for Conversational AI API" 2>/dev/null || true
    
    # Construct API endpoint
    export API_ENDPOINT="https://$API_ID.execute-api.$AWS_REGION.amazonaws.com/prod"
    
    log INFO "API Gateway deployed successfully"
    log INFO "API Endpoint: $API_ENDPOINT/chat"
    
    # Save API endpoint to environment file
    echo "API_ID=$API_ID" >> "${SCRIPT_DIR}/.env"
    echo "API_ENDPOINT=$API_ENDPOINT" >> "${SCRIPT_DIR}/.env"
}

# Create test scripts
create_test_scripts() {
    log INFO "Creating test scripts..."
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log INFO "[DRY RUN] Would create test scripts"
        return
    fi
    
    # Create interactive test script
    cat > "${SCRIPT_DIR}/test_conversational_ai.py" << EOF
#!/usr/bin/env python3
import requests
import json
import uuid
import sys

# Configuration
API_ENDPOINT = "${API_ENDPOINT}/chat"

def send_message(message, session_id=None, user_id="test_user"):
    """Send a message to the conversational AI API"""
    
    if not session_id:
        session_id = str(uuid.uuid4())
    
    payload = {
        "message": message,
        "session_id": session_id,
        "user_id": user_id
    }
    
    try:
        response = requests.post(
            API_ENDPOINT,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json(), session_id
        else:
            print(f"Error: {response.status_code} - {response.text}")
            return None, session_id
            
    except Exception as e:
        print(f"Request failed: {e}")
        return None, session_id

def interactive_chat():
    """Interactive chat session"""
    
    print("ü§ñ Conversational AI Chat")
    print("Type 'quit' to exit, 'new' to start a new session")
    print("-" * 50)
    
    session_id = str(uuid.uuid4())
    
    while True:
        user_input = input("You: ").strip()
        
        if user_input.lower() == 'quit':
            break
        elif user_input.lower() == 'new':
            session_id = str(uuid.uuid4())
            print("üîÑ Started new conversation session")
            continue
        elif not user_input:
            continue
        
        print("ü§ñ Thinking...")
        
        response, session_id = send_message(user_input, session_id)
        
        if response:
            print(f"AI: {response['response']}")
            print(f"Session: {session_id[:8]}...")
        else:
            print("‚ùå Failed to get response")
        
        print()

def run_test_conversation():
    """Run automated test conversation"""
    
    print("üß™ Running test conversation...")
    
    test_messages = [
        "Hello! What can you help me with?",
        "Can you explain what machine learning is?",
        "What are some practical applications of AI?",
        "Thank you for the information!"
    ]
    
    session_id = str(uuid.uuid4())
    
    for i, message in enumerate(test_messages, 1):
        print(f"\\n{i}. User: {message}")
        
        response, session_id = send_message(message, session_id)
        
        if response:
            print(f"   AI: {response['response']}")
        else:
            print("   ‚ùå Failed to get response")

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        run_test_conversation()
    else:
        interactive_chat()
EOF
    
    chmod +x "${SCRIPT_DIR}/test_conversational_ai.py"
    
    log INFO "Test scripts created successfully"
    log INFO "Run 'python3 ${SCRIPT_DIR}/test_conversational_ai.py test' for automated testing"
    log INFO "Run 'python3 ${SCRIPT_DIR}/test_conversational_ai.py' for interactive chat"
}

# Main deployment function
main() {
    log INFO "=== Starting Conversational AI Deployment ==="
    
    check_prerequisites
    setup_environment
    check_bedrock_access
    create_dynamodb_table
    create_iam_role
    create_lambda_function
    create_api_gateway
    create_test_scripts
    
    log INFO "=== Deployment Complete ==="
    log INFO ""
    log INFO "üéâ Conversational AI application deployed successfully!"
    log INFO ""
    log INFO "üìã Deployment Summary:"
    log INFO "  ‚Ä¢ DynamoDB Table: $TABLE_NAME"
    log INFO "  ‚Ä¢ Lambda Function: $LAMBDA_FUNCTION_NAME"
    log INFO "  ‚Ä¢ IAM Role: $IAM_ROLE_NAME"
    log INFO "  ‚Ä¢ API Gateway: $API_NAME ($API_ID)"
    log INFO "  ‚Ä¢ API Endpoint: $API_ENDPOINT/chat"
    log INFO "  ‚Ä¢ Claude Model: $CLAUDE_MODEL_ID"
    log INFO ""
    log INFO "üß™ Testing:"
    log INFO "  ‚Ä¢ Automated test: python3 ${SCRIPT_DIR}/test_conversational_ai.py test"
    log INFO "  ‚Ä¢ Interactive chat: python3 ${SCRIPT_DIR}/test_conversational_ai.py"
    log INFO ""
    log INFO "üóëÔ∏è  Cleanup:"
    log INFO "  ‚Ä¢ Run: ${SCRIPT_DIR}/destroy.sh"
    log INFO ""
    log INFO "üìã Environment details saved to: ${SCRIPT_DIR}/.env"
    log INFO "üìã Full deployment log: $LOG_FILE"
}

# Run main function
main "$@"