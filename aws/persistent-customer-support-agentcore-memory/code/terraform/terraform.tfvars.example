# ================================================================
# Example Terraform Variables Configuration
# Recipe: Persistent Customer Support Agent with Bedrock AgentCore Memory
# 
# Copy this file to terraform.tfvars and customize the values
# for your environment.
# ================================================================

# ================================================================
# GENERAL CONFIGURATION
# ================================================================

aws_region = "us-east-1"

tags = {
  Project     = "CustomerSupportAgent"
  Environment = "development"
  Owner       = "YourName"
  CostCenter  = "CustomerSupport"
  Recipe      = "persistent-customer-support-agentcore-memory"
  ManagedBy   = "Terraform"
}

# ================================================================
# BEDROCK AGENTCORE MEMORY CONFIGURATION
# ================================================================

memory_name_prefix           = "customer-support-memory"
memory_event_expiry_duration = "P30D"  # 30 days in ISO 8601 format

# Memory strategies (enable the ones you need)
enable_memory_summarization = true
enable_semantic_memory      = true
enable_user_preferences     = true
enable_custom_extraction    = true

# Custom extraction prompt for domain-specific insights
custom_extraction_prompt = "Extract the following from customer support conversations: 1) Customer preferences and requirements, 2) Technical issues and their resolutions, 3) Product interests and purchasing intent, 4) Satisfaction levels and feedback. Focus on actionable insights that improve future support interactions."

# ================================================================
# BEDROCK MODEL CONFIGURATION
# ================================================================

# Choose your preferred Bedrock foundation model
bedrock_model_id = "anthropic.claude-3-haiku-20240307-v1:0"
# Other options:
# "anthropic.claude-3-sonnet-20240229-v1:0"  # More capable but higher cost
# "anthropic.claude-v2:1"                    # Previous generation
# "amazon.titan-text-express-v1"             # Amazon's model
# "ai21.j2-ultra-v1"                        # AI21 Labs model
# "cohere.command-text-v14"                 # Cohere model

bedrock_max_tokens = 500

# ================================================================
# DYNAMODB CONFIGURATION
# ================================================================

table_name_prefix = "customer-data"

# Choose billing mode based on your usage patterns
dynamodb_billing_mode = "PROVISIONED"  # or "PAY_PER_REQUEST"

# Only used with PROVISIONED billing mode
dynamodb_read_capacity  = 5   # Adjust based on expected read volume
dynamodb_write_capacity = 5   # Adjust based on expected write volume

# Security and backup settings
enable_dynamodb_encryption     = true
enable_point_in_time_recovery = true

# ================================================================
# LAMBDA CONFIGURATION
# ================================================================

lambda_function_name_prefix = "support-agent"
lambda_runtime             = "python3.11"
lambda_timeout             = 30    # seconds
lambda_memory_size         = 512   # MB
lambda_log_retention_days  = 14    # days

# Advanced Lambda settings
enable_lambda_dlq           = true
lambda_reserved_concurrency = null  # Set to a number to limit concurrency

# ================================================================
# API GATEWAY CONFIGURATION
# ================================================================

api_name_prefix = "support-api"
api_stage_name  = "prod"
api_log_retention_days = 14

# API Gateway performance and security
enable_api_caching   = false               # Enable for better performance
api_cache_cluster_size = "0.5"            # GB, only used if caching enabled

enable_api_throttling       = true
api_throttle_rate_limit     = 1000         # requests per second
api_throttle_burst_limit    = 2000         # burst capacity

# CORS configuration
enable_cors             = true
cors_allowed_origins    = ["*"]            # Restrict in production
cors_allowed_methods    = ["POST", "OPTIONS"]
cors_allowed_headers    = ["Content-Type", "X-Amz-Date", "Authorization", "X-Api-Key", "X-Amz-Security-Token"]

# ================================================================
# MONITORING AND ALERTING
# ================================================================

enable_monitoring = true

# CloudWatch alarm thresholds
lambda_error_threshold     = 5
api_4xx_error_threshold   = 10
api_5xx_error_threshold   = 5
lambda_duration_threshold = 25000  # milliseconds

# SNS topic ARN for alarm notifications (optional)
# alarm_notification_topic = "arn:aws:sns:us-east-1:123456789012:alerts"
alarm_notification_topic = ""

# ================================================================
# SAMPLE DATA CONFIGURATION
# ================================================================

# Set to false in production to avoid creating test data
create_sample_data = true

# Customize sample customer data for your use case
sample_customers = [
  {
    customer_id       = "customer-001"
    name             = "Sarah Johnson"
    email            = "sarah.johnson@example.com"
    preferred_channel = "chat"
    product_interests = ["enterprise-software", "analytics"]
    support_tier     = "premium"
  },
  {
    customer_id       = "customer-002"
    name             = "Michael Chen"
    email            = "michael.chen@example.com"
    preferred_channel = "email"
    product_interests = ["mobile-apps", "integration"]
    support_tier     = "standard"
  }
]

# ================================================================
# SECURITY CONFIGURATION
# ================================================================

# VPC configuration (optional - for enhanced security)
enable_vpc_endpoints = false
# vpc_id     = "vpc-xxxxxxxxx"
# subnet_ids = ["subnet-xxxxxxxxx", "subnet-yyyyyyyyy"]

# AWS WAF (optional - for API protection)
enable_waf      = false
waf_rate_limit  = 10000  # requests per 5-minute period

# API Key requirement (optional - for access control)
enable_api_key_required           = false
api_key_usage_plan_quota_limit    = 1000
api_key_usage_plan_quota_period   = "DAY"

# ================================================================
# COST OPTIMIZATION
# ================================================================

enable_cost_allocation_tags = true
cost_center                = "CustomerSupport"

# Budget monitoring (optional)
enable_budget_alerts = false
budget_limit        = 100      # USD per month
# budget_alert_email  = "alerts@yourcompany.com"

# ================================================================
# DEVELOPMENT VS PRODUCTION SETTINGS
# ================================================================

# For development environments, consider these settings:
# - Lower DynamoDB capacity (1-2 units)
# - Shorter log retention (7 days)
# - Disable monitoring and alerting
# - Use PAY_PER_REQUEST billing for DynamoDB
# - Enable sample data creation

# For production environments, consider these settings:
# - Higher DynamoDB capacity based on usage
# - Longer log retention (30+ days)
# - Enable comprehensive monitoring
# - Use PROVISIONED billing with auto-scaling
# - Disable sample data creation
# - Enable VPC endpoints and WAF
# - Configure proper SNS notifications
# - Set up API keys for access control

# ================================================================
# REGIONAL CONSIDERATIONS
# ================================================================

# Ensure your chosen region supports:
# - Amazon Bedrock AgentCore (preview service)
# - Your selected Bedrock foundation models
# - All other required AWS services

# Bedrock AgentCore is currently available in:
# - us-east-1 (N. Virginia)
# - us-west-2 (Oregon)
# - eu-west-1 (Ireland)
# - eu-central-1 (Frankfurt)
# - ap-southeast-1 (Singapore)
# - ap-northeast-1 (Tokyo)

# ================================================================
# PERFORMANCE TUNING
# ================================================================

# For high-volume environments, consider:
# - Increasing Lambda memory and timeout
# - Using DynamoDB auto-scaling
# - Enabling API Gateway caching
# - Implementing connection pooling
# - Using Lambda provisioned concurrency
# - Optimizing Bedrock model selection

# For cost optimization, consider:
# - Using smaller Lambda memory sizes
# - Implementing intelligent caching strategies
# - Using cheaper Bedrock models where appropriate
# - Optimizing DynamoDB read/write patterns
# - Implementing request batching