# Infrastructure Manager Configuration for Conversational AI Training Data Generation
# This configuration deploys all resources needed for automated conversation generation
# using Gemini AI and Cloud Storage with serverless orchestration

# Import Google Cloud provider resources
imports:
  - path: 'projects/PROJECT_ID/global/gconfig'

metadata:
  version: '1.0'
  description: 'Conversational AI Training Data Generation with Gemini and Cloud Storage'
  author: 'Infrastructure Manager Generator'
  recipe_id: 'a7c9e2d5'

# Input parameters for customization
properties:
  - project_id:
      type: string
      description: 'GCP Project ID for resource deployment'
      default: 'conv-ai-training-$(date +%s)'
  - region:
      type: string
      description: 'GCP region for resource deployment'
      default: 'us-central1'
  - zone:
      type: string
      description: 'GCP zone for compute resources'
      default: 'us-central1-a'
  - bucket_suffix:
      type: string
      description: 'Unique suffix for storage bucket naming'
      default: '$(openssl rand -hex 3)'
  - function_suffix:
      type: string
      description: 'Unique suffix for Cloud Function naming'
      default: '$(openssl rand -hex 3)'

resources:
  # Enable required Google Cloud APIs
  - name: compute-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/compute.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: functions-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/cloudfunctions.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: storage-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/storage.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: aiplatform-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/aiplatform.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: cloudbuild-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/cloudbuild.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: logging-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/logging.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  - name: monitoring-api
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project-id.name)/services/monitoring.googleapis.com
      consumerId: project:$(ref.project-id.name)
    metadata:
      dependsOn:
        - project-id

  # Cloud Storage bucket for training data organization
  - name: training-data-bucket
    type: gcp-types/storage-v1:buckets
    properties:
      name: training-data-$(ref.bucket-suffix)
      project: $(ref.project-id.name)
      location: $(ref.region)
      storageClass: STANDARD
      versioning:
        enabled: true
      lifecycle:
        rule:
          - action:
              type: Delete
            condition:
              age: 365
              isLive: false
      iamConfiguration:
        uniformBucketLevelAccess:
          enabled: true
      cors:
        - origin:
            - '*'
          method:
            - GET
            - POST
            - PUT
            - DELETE
          responseHeader:
            - Content-Type
            - Access-Control-Allow-Origin
          maxAgeSeconds: 3600
    metadata:
      dependsOn:
        - storage-api
      description: 'Primary storage bucket for conversational training data with versioning and lifecycle management'

  # Service Account for Cloud Functions
  - name: conversation-generator-sa
    type: gcp-types/iam-v1:projects.serviceAccounts
    properties:
      accountId: conversation-generator-sa
      project: $(ref.project-id.name)
      serviceAccount:
        displayName: 'Conversation Generator Service Account'
        description: 'Service account for Cloud Functions handling conversation generation'
    metadata:
      dependsOn:
        - project-id

  # IAM binding for Storage Admin access
  - name: storage-admin-binding
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project-id.name)
      role: roles/storage.admin
      member: serviceAccount:$(ref.conversation-generator-sa.email)
    metadata:
      dependsOn:
        - conversation-generator-sa

  # IAM binding for Vertex AI access
  - name: vertex-ai-binding
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project-id.name)
      role: roles/aiplatform.user
      member: serviceAccount:$(ref.conversation-generator-sa.email)
    metadata:
      dependsOn:
        - conversation-generator-sa

  # IAM binding for Logging access
  - name: logging-binding
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project-id.name)
      role: roles/logging.logWriter
      member: serviceAccount:$(ref.conversation-generator-sa.email)
    metadata:
      dependsOn:
        - conversation-generator-sa

  # Create conversation templates in Cloud Storage
  - name: conversation-templates
    type: gcp-types/storage-v1:objects
    properties:
      bucket: $(ref.training-data-bucket.name)
      name: 'templates/conversation_templates.json'
      contentType: 'application/json'
      # Base64 encoded JSON content for conversation templates
      data: |
        ewogICJ0ZW1wbGF0ZXMiOiBbCiAgICB7CiAgICAgICJzY2VuYXJpbyI6ICJjdXN0b21lcl9zdXBwb3J0IiwKICAgICAgImNvbnRleHQiOiAiVGVjaG5pY2FsIHN1cHBvcnQgZm9yIGEgc29mdHdhcmUgYXBwbGljYXRpb24iLAogICAgICAidXNlcl9pbnRlbnRzIjogWyJidWdfcmVwb3J0IiwgImZlYXR1cmVfcmVxdWVzdCIsICJhY2NvdW50X2lzc3VlIl0sCiAgICAgICJjb252ZXJzYXRpb25fbGVuZ3RoIjogIjMtNSBleGNoYW5nZXMiLAogICAgICAidG9uZSI6ICJwcm9mZXNzaW9uYWwsIGhlbHBmdWwiCiAgICB9LAogICAgewogICAgICAic2NlbmFyaW8iOiAiZV9jb21tZXJjZSIsCiAgICAgICJjb250ZXh0IjogIk9ubGluZSBzaG9wcGluZyBhc3Npc3RhbmNlIGFuZCBwcm9kdWN0IGlucXVpcmllcyIsCiAgICAgICJ1c2VyX2ludGVudHMiOiBbInByb2R1Y3Rfc2VhcmNoIiwgIm9yZGVyX3N0YXR1cyIsICJyZXR1cm5fcmVxdWVzdCJdLAogICAgICAiY29udmVyc2F0aW9uX2xlbmd0aCI6ICIyLTQgZXhjaGFuZ2VzIiwKICAgICAgInRvbmUiOiAiZnJpZW5kbHksIHNhbGVzLW9yaWVudGVkIgogICAgfSwKICAgIHsKICAgICAgInNjZW5hcmlvIjogImhlYWx0aGNhcmUiLAogICAgICAiY29udGV4dCI6ICJHZW5lcmFsIGhlYWx0aCBpbmZvcm1hdGlvbiBhbmQgYXBwb2ludG1lbnQgc2NoZWR1bGluZyIsCiAgICAgICJ1c2VyX2ludGVudHMiOiBbInN5bXB0b21faW5xdWlyeSIsICJhcHBvaW50bWVudF9ib29raW5nIiwgIm1lZGljYXRpb25faW5mbyJdLAogICAgICAiY29udmVyc2F0aW9uX2xlbmd0aCI6ICI0LTYgZXhjaGFuZ2VzIiwKICAgICAgInRvbmUiOiAiZW1wYXRoZXRpYywgcHJvZmVzc2lvbmFsIgogICAgfQogIF0KfQ==
    metadata:
      dependsOn:
        - training-data-bucket
      description: 'Conversation templates defining scenarios, intents, and conversation patterns'

  # Create folder structure placeholder files in Cloud Storage
  - name: raw-conversations-folder
    type: gcp-types/storage-v1:objects
    properties:
      bucket: $(ref.training-data-bucket.name)
      name: 'raw-conversations/.keep'
      contentType: 'text/plain'
      data: ''
    metadata:
      dependsOn:
        - training-data-bucket

  - name: processed-conversations-folder
    type: gcp-types/storage-v1:objects
    properties:
      bucket: $(ref.training-data-bucket.name)
      name: 'processed-conversations/.keep'
      contentType: 'text/plain'
      data: ''
    metadata:
      dependsOn:
        - training-data-bucket

  - name: formatted-training-folder
    type: gcp-types/storage-v1:objects
    properties:
      bucket: $(ref.training-data-bucket.name)
      name: 'formatted-training/.keep'
      contentType: 'text/plain'
      data: ''
    metadata:
      dependsOn:
        - training-data-bucket

  # Cloud Function for conversation generation
  - name: conversation-generator-function
    type: gcp-types/cloudfunctions-v1:projects.locations.functions
    properties:
      parent: projects/$(ref.project-id.name)/locations/$(ref.region)
      function:
        name: conversation-generator-$(ref.function-suffix)
        description: 'Serverless function for generating conversational training data using Gemini AI'
        sourceArchiveUrl: 'gs://$(ref.source-code-bucket.name)/conversation-generator-source.zip'
        entryPoint: 'generate_conversations'
        runtime: 'python312'
        timeout: '540s'
        availableMemoryMb: 1024
        serviceAccountEmail: $(ref.conversation-generator-sa.email)
        environmentVariables:
          BUCKET_NAME: $(ref.training-data-bucket.name)
          GCP_PROJECT: $(ref.project-id.name)
          FUNCTION_REGION: $(ref.region)
        httpsTrigger:
          securityLevel: SECURE_ALWAYS
        maxInstances: 10
        ingressSettings: ALLOW_ALL
        labels:
          environment: 'production'
          component: 'conversation-generator'
          recipe-id: 'a7c9e2d5'
    metadata:
      dependsOn:
        - functions-api
        - conversation-generator-sa
        - training-data-bucket
        - source-code-bucket
      description: 'HTTP-triggered Cloud Function for generating conversations using Vertex AI Gemini'

  # Cloud Function for data processing
  - name: data-processor-function
    type: gcp-types/cloudfunctions-v1:projects.locations.functions
    properties:
      parent: projects/$(ref.project-id.name)/locations/$(ref.region)
      function:
        name: data-processor-$(ref.function-suffix)
        description: 'Serverless function for processing and formatting conversational training data'
        sourceArchiveUrl: 'gs://$(ref.source-code-bucket.name)/data-processor-source.zip'
        entryPoint: 'process_conversations'
        runtime: 'python312'
        timeout: '540s'
        availableMemoryMb: 1024
        serviceAccountEmail: $(ref.conversation-generator-sa.email)
        httpsTrigger:
          securityLevel: SECURE_ALWAYS
        maxInstances: 5
        ingressSettings: ALLOW_ALL
        labels:
          environment: 'production'
          component: 'data-processor'
          recipe-id: 'a7c9e2d5'
    metadata:
      dependsOn:
        - functions-api
        - conversation-generator-sa
        - training-data-bucket
        - source-code-bucket
      description: 'HTTP-triggered Cloud Function for processing conversations into training-ready formats'

  # Source code bucket for Cloud Functions deployment
  - name: source-code-bucket
    type: gcp-types/storage-v1:buckets
    properties:
      name: source-code-$(ref.bucket-suffix)
      project: $(ref.project-id.name)
      location: $(ref.region)
      storageClass: STANDARD
      lifecycle:
        rule:
          - action:
              type: Delete
            condition:
              age: 30
    metadata:
      dependsOn:
        - storage-api
      description: 'Temporary bucket for Cloud Function source code deployment'

  # Log-based metrics for monitoring conversation generation
  - name: conversation-generation-success-metric
    type: gcp-types/logging-v2:projects.metrics
    properties:
      parent: projects/$(ref.project-id.name)
      metric:
        name: 'conversation_generation_success'
        description: 'Successful conversation generation events'
        filter: |
          resource.type="cloud_function"
          resource.labels.function_name="$(ref.conversation-generator-function.name)"
          jsonPayload.status="success"
        metricDescriptor:
          metricKind: GAUGE
          valueType: INT64
          displayName: 'Conversation Generation Success'
        labelExtractors:
          scenario: 'EXTRACT(jsonPayload.scenario)'
          function_name: 'EXTRACT(resource.labels.function_name)'
    metadata:
      dependsOn:
        - logging-api
        - conversation-generator-function
      description: 'Monitoring metric for successful conversation generation events'

  - name: conversation-generation-error-metric
    type: gcp-types/logging-v2:projects.metrics
    properties:
      parent: projects/$(ref.project-id.name)
      metric:
        name: 'conversation_generation_errors'
        description: 'Failed conversation generation events'
        filter: |
          resource.type="cloud_function"
          resource.labels.function_name="$(ref.conversation-generator-function.name)"
          severity="ERROR"
        metricDescriptor:
          metricKind: GAUGE
          valueType: INT64
          displayName: 'Conversation Generation Errors'
        labelExtractors:
          function_name: 'EXTRACT(resource.labels.function_name)'
          error_type: 'EXTRACT(jsonPayload.error_type)'
    metadata:
      dependsOn:
        - logging-api
        - conversation-generator-function
      description: 'Monitoring metric for failed conversation generation events'

  # Cloud Monitoring alerting policy for error detection
  - name: conversation-generation-alert-policy
    type: gcp-types/monitoring-v1:projects.alertPolicies
    properties:
      parent: projects/$(ref.project-id.name)
      alertPolicy:
        displayName: 'Conversation Generation Error Alert'
        documentation:
          content: 'Alert triggered when conversation generation functions experience high error rates'
          mimeType: 'text/markdown'
        conditions:
          - displayName: 'High Error Rate Condition'
            conditionThreshold:
              filter: 'metric.type="logging.googleapis.com/user/conversation_generation_errors" resource.type="cloud_function"'
              comparison: COMPARISON_GREATER_THAN
              thresholdValue: 5
              duration: '300s'
              aggregations:
                - alignmentPeriod: '300s'
                  perSeriesAligner: ALIGN_RATE
                  crossSeriesReducer: REDUCE_SUM
        combiner: OR
        enabled: true
        notificationChannels: []
    metadata:
      dependsOn:
        - monitoring-api
        - conversation-generation-error-metric
      description: 'Alerting policy for monitoring conversation generation function errors'

# Outputs for verification and integration
outputs:
  - name: project_id
    value: $(ref.project-id.name)
    description: 'GCP Project ID used for deployment'

  - name: region
    value: $(ref.region)
    description: 'GCP region where resources are deployed'

  - name: training_data_bucket
    value: $(ref.training-data-bucket.name)
    description: 'Cloud Storage bucket name for training data storage'

  - name: conversation_generator_function_name
    value: $(ref.conversation-generator-function.name)
    description: 'Name of the conversation generator Cloud Function'

  - name: conversation_generator_function_url
    value: $(ref.conversation-generator-function.httpsTrigger.url)
    description: 'HTTP trigger URL for the conversation generator function'

  - name: data_processor_function_name
    value: $(ref.data-processor-function.name)
    description: 'Name of the data processor Cloud Function'

  - name: data_processor_function_url
    value: $(ref.data-processor-function.httpsTrigger.url)
    description: 'HTTP trigger URL for the data processor function'

  - name: service_account_email
    value: $(ref.conversation-generator-sa.email)
    description: 'Service account email for Cloud Functions'

  - name: source_code_bucket
    value: $(ref.source-code-bucket.name)
    description: 'Temporary bucket for Cloud Function source code'

  - name: conversation_templates_path
    value: 'gs://$(ref.training-data-bucket.name)/templates/conversation_templates.json'
    description: 'Cloud Storage path to conversation templates'

  - name: raw_conversations_path
    value: 'gs://$(ref.training-data-bucket.name)/raw-conversations/'
    description: 'Cloud Storage path for raw conversation data'

  - name: processed_conversations_path
    value: 'gs://$(ref.training-data-bucket.name)/processed-conversations/'
    description: 'Cloud Storage path for processed conversation data'

  - name: formatted_training_path
    value: 'gs://$(ref.training-data-bucket.name)/formatted-training/'
    description: 'Cloud Storage path for formatted training data'

  - name: success_metric_name
    value: $(ref.conversation-generation-success-metric.name)
    description: 'Log-based metric name for successful conversation generation'

  - name: error_metric_name
    value: $(ref.conversation-generation-error-metric.name)
    description: 'Log-based metric name for conversation generation errors'

  - name: alert_policy_name
    value: $(ref.conversation-generation-alert-policy.name)
    description: 'Cloud Monitoring alert policy for error detection'

# Deployment metadata
deployment_info:
  version: '1.0'
  created_by: 'Infrastructure Manager Generator'
  recipe_title: 'Conversational AI Training Data Generation with Gemini and Cloud Storage'
  recipe_id: 'a7c9e2d5'
  estimated_deployment_time: '10-15 minutes'
  estimated_cost: '$5-15 for initial deployment and testing'
  prerequisites:
    - 'GCP Project with billing enabled'
    - 'Infrastructure Manager API enabled'
    - 'Appropriate IAM permissions for resource creation'
  post_deployment_steps:
    - 'Upload Cloud Function source code to source code bucket'
    - 'Test conversation generation endpoints'
    - 'Validate training data organization in Cloud Storage'
    - 'Configure monitoring and alerting notifications'