#!/bin/bash

# Deploy script for Smart Product Review Analysis with Translation and Natural Language AI
# Recipe: smart-product-review-analysis-translation-natural-language
# Provider: GCP
# Generated by: recipe-generator-version 1.3

set -euo pipefail

# Script configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="${SCRIPT_DIR}/deploy.log"
ERROR_LOG="${SCRIPT_DIR}/deploy_errors.log"

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging functions
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1" | tee -a "$LOG_FILE"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING:${NC} $1" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1" | tee -a "$ERROR_LOG"
}

info() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] INFO:${NC} $1" | tee -a "$LOG_FILE"
}

# Function to check prerequisites
check_prerequisites() {
    info "Checking prerequisites..."
    
    # Check if gcloud CLI is installed
    if ! command -v gcloud &> /dev/null; then
        error "Google Cloud CLI (gcloud) is not installed. Please install it first."
        exit 1
    fi
    
    # Check if bq CLI is available
    if ! command -v bq &> /dev/null; then
        error "BigQuery CLI (bq) is not installed. Please install it first."
        exit 1
    fi
    
    # Check if curl is available
    if ! command -v curl &> /dev/null; then
        error "curl is not installed. Please install it first."
        exit 1
    fi
    
    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        error "jq is not installed. Please install it first."
        exit 1
    fi
    
    # Check if openssl is available
    if ! command -v openssl &> /dev/null; then
        error "openssl is not installed. Please install it first."
        exit 1
    fi
    
    # Check if user is authenticated with gcloud
    if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" | grep -q .; then
        error "No active gcloud authentication found. Please run 'gcloud auth login' first."
        exit 1
    fi
    
    log "Prerequisites check completed successfully"
}

# Function to set up environment variables
setup_environment() {
    info "Setting up environment variables..."
    
    # Set default values or prompt for user input
    if [[ -z "${PROJECT_ID:-}" ]]; then
        if [[ -n "${1:-}" ]]; then
            export PROJECT_ID="$1"
        else
            export PROJECT_ID="review-analysis-$(date +%s)"
            warn "No PROJECT_ID provided, using default: $PROJECT_ID"
        fi
    fi
    
    export REGION="${REGION:-us-central1}"
    export ZONE="${ZONE:-us-central1-a}"
    
    # Generate unique suffix for resource names
    export RANDOM_SUFFIX=$(openssl rand -hex 3)
    
    # Set dataset name
    export DATASET_NAME="product_reviews_${RANDOM_SUFFIX}"
    export FUNCTION_NAME="review-analysis-${RANDOM_SUFFIX}"
    
    log "Environment variables configured:"
    log "  PROJECT_ID: $PROJECT_ID"
    log "  REGION: $REGION"
    log "  ZONE: $ZONE"
    log "  DATASET_NAME: $DATASET_NAME"
    log "  FUNCTION_NAME: $FUNCTION_NAME"
}

# Function to configure GCP project
configure_project() {
    info "Configuring GCP project..."
    
    # Set default project and region
    gcloud config set project "${PROJECT_ID}" 2>/dev/null || {
        error "Failed to set project ${PROJECT_ID}. Please check if the project exists and you have access."
        exit 1
    }
    
    gcloud config set compute/region "${REGION}" 2>/dev/null
    gcloud config set compute/zone "${ZONE}" 2>/dev/null
    
    log "GCP project configuration completed"
}

# Function to enable required APIs
enable_apis() {
    info "Enabling required APIs..."
    
    local apis=(
        "cloudfunctions.googleapis.com"
        "translate.googleapis.com"
        "language.googleapis.com"
        "bigquery.googleapis.com"
        "cloudbuild.googleapis.com"
    )
    
    for api in "${apis[@]}"; do
        info "Enabling API: $api"
        if gcloud services enable "$api" --quiet; then
            log "Successfully enabled $api"
        else
            error "Failed to enable $api"
            exit 1
        fi
    done
    
    # Wait for APIs to be fully enabled
    info "Waiting for APIs to be fully enabled..."
    sleep 30
    
    log "All required APIs enabled successfully"
}

# Function to create BigQuery resources
create_bigquery_resources() {
    info "Creating BigQuery resources..."
    
    # Create BigQuery dataset
    info "Creating BigQuery dataset: $DATASET_NAME"
    if bq mk --dataset \
        --description="Dataset for multilingual product review analysis" \
        --location="${REGION}" \
        "${PROJECT_ID}:${DATASET_NAME}"; then
        log "BigQuery dataset created successfully"
    else
        error "Failed to create BigQuery dataset"
        exit 1
    fi
    
    # Create the review analysis table
    info "Creating BigQuery table: review_analysis"
    if bq mk --table \
        "${PROJECT_ID}:${DATASET_NAME}.review_analysis" \
        review_id:STRING,original_text:STRING,original_language:STRING,translated_text:STRING,sentiment_score:FLOAT,sentiment_magnitude:FLOAT,sentiment_label:STRING,entities:STRING,processing_timestamp:TIMESTAMP; then
        log "BigQuery table created successfully"
    else
        error "Failed to create BigQuery table"
        exit 1
    fi
}

# Function to prepare Cloud Function code
prepare_function_code() {
    info "Preparing Cloud Function code..."
    
    local function_dir="${SCRIPT_DIR}/../function"
    mkdir -p "$function_dir"
    cd "$function_dir"
    
    # Create requirements.txt
    cat > requirements.txt << 'EOF'
google-cloud-translate==3.15.5
google-cloud-language==2.13.4
google-cloud-bigquery==3.25.0
functions-framework==3.8.1
EOF
    
    # Create main.py with the function code
    cat > main.py << 'EOF'
import functions_framework
import json
import logging
from datetime import datetime
from google.cloud import translate_v2 as translate
from google.cloud import language_v1
from google.cloud import bigquery

# Initialize clients
translate_client = translate.Client()
language_client = language_v1.LanguageServiceClient()
bigquery_client = bigquery.Client()

logging.basicConfig(level=logging.INFO)

@functions_framework.http
def analyze_review(request):
    """Analyze product review with translation and sentiment analysis."""
    try:
        # Parse request JSON
        request_json = request.get_json(silent=True)
        if not request_json:
            return {'error': 'Invalid JSON payload'}, 400
        
        review_id = request_json.get('review_id')
        review_text = request_json.get('review_text')
        
        if not review_id or not review_text:
            return {'error': 'Missing review_id or review_text'}, 400
        
        # Detect source language
        detection = translate_client.detect_language(review_text)
        source_language = detection['language']
        confidence = detection['confidence']
        
        logging.info(f"Detected language: {source_language} (confidence: {confidence})")
        
        # Translate to English if not already English
        translated_text = review_text
        if source_language != 'en':
            translation = translate_client.translate(
                review_text,
                target_language='en',
                source_language=source_language
            )
            translated_text = translation['translatedText']
        
        # Perform sentiment analysis on translated text
        document = language_v1.Document(
            content=translated_text,
            type_=language_v1.Document.Type.PLAIN_TEXT
        )
        
        # Analyze sentiment
        sentiment_response = language_client.analyze_sentiment(
            request={"document": document}
        )
        sentiment = sentiment_response.document_sentiment
        
        # Determine sentiment label
        if sentiment.score > 0.1:
            sentiment_label = 'positive'
        elif sentiment.score < -0.1:
            sentiment_label = 'negative'
        else:
            sentiment_label = 'neutral'
        
        # Extract entities
        entities_response = language_client.analyze_entities(
            request={"document": document}
        )
        
        entities = []
        for entity in entities_response.entities:
            entities.append({
                'name': entity.name,
                'type': entity.type_.name,
                'salience': entity.salience
            })
        
        # Prepare data for BigQuery
        analysis_result = {
            'review_id': review_id,
            'original_text': review_text,
            'original_language': source_language,
            'translated_text': translated_text,
            'sentiment_score': sentiment.score,
            'sentiment_magnitude': sentiment.magnitude,
            'sentiment_label': sentiment_label,
            'entities': json.dumps(entities),
            'processing_timestamp': datetime.utcnow().isoformat()
        }
        
        # Insert into BigQuery
        dataset_id = request_json.get('dataset_id', 'product_reviews')
        table_id = 'review_analysis'
        
        table_ref = bigquery_client.dataset(dataset_id).table(table_id)
        table = bigquery_client.get_table(table_ref)
        
        errors = bigquery_client.insert_rows_json(table, [analysis_result])
        
        if errors:
            logging.error(f"BigQuery insert errors: {errors}")
            return {'error': 'Failed to insert data into BigQuery'}, 500
        
        logging.info(f"Successfully processed review {review_id}")
        
        return {
            'status': 'success',
            'review_id': review_id,
            'original_language': source_language,
            'sentiment_label': sentiment_label,
            'sentiment_score': sentiment.score,
            'entities_count': len(entities)
        }
        
    except Exception as e:
        logging.error(f"Error processing review: {str(e)}")
        return {'error': str(e)}, 500
EOF
    
    log "Cloud Function code prepared successfully"
}

# Function to deploy Cloud Function
deploy_function() {
    info "Deploying Cloud Function..."
    
    local function_dir="${SCRIPT_DIR}/../function"
    cd "$function_dir"
    
    # Deploy the function
    if gcloud functions deploy "${FUNCTION_NAME}" \
        --runtime python312 \
        --trigger-http \
        --allow-unauthenticated \
        --source . \
        --entry-point analyze_review \
        --memory 512MB \
        --timeout 60s \
        --set-env-vars DATASET_ID="${DATASET_NAME}" \
        --region="${REGION}" \
        --quiet; then
        log "Cloud Function deployed successfully"
    else
        error "Failed to deploy Cloud Function"
        exit 1
    fi
    
    # Get function URL
    export FUNCTION_URL=$(gcloud functions describe "${FUNCTION_NAME}" \
        --region="${REGION}" \
        --format="value(httpsTrigger.url)")
    
    log "Function URL: ${FUNCTION_URL}"
    
    # Save deployment info
    echo "PROJECT_ID=${PROJECT_ID}" > "${SCRIPT_DIR}/deployment_info.env"
    echo "REGION=${REGION}" >> "${SCRIPT_DIR}/deployment_info.env"
    echo "DATASET_NAME=${DATASET_NAME}" >> "${SCRIPT_DIR}/deployment_info.env"
    echo "FUNCTION_NAME=${FUNCTION_NAME}" >> "${SCRIPT_DIR}/deployment_info.env"
    echo "FUNCTION_URL=${FUNCTION_URL}" >> "${SCRIPT_DIR}/deployment_info.env"
}

# Function to create sample data and test
create_sample_data() {
    info "Creating sample review data and testing the deployment..."
    
    local sample_dir="${SCRIPT_DIR}/../samples"
    mkdir -p "$sample_dir"
    cd "$sample_dir"
    
    # Create sample review data
    cat > sample_reviews.json << EOF
[
  {
    "review_id": "rev_001",
    "review_text": "Este producto es excelente. La calidad es muy buena y el servicio al cliente fue fantástico.",
    "dataset_id": "${DATASET_NAME}"
  },
  {
    "review_id": "rev_002", 
    "review_text": "Das Produkt ist okay, aber der Versand war zu langsam. Könnte besser sein.",
    "dataset_id": "${DATASET_NAME}"
  },
  {
    "review_id": "rev_003",
    "review_text": "Cette montre est magnifique! Design élégant et fonctionnalités parfaites.",
    "dataset_id": "${DATASET_NAME}"
  },
  {
    "review_id": "rev_004",
    "review_text": "The product quality is terrible. Broke after one week. Very disappointing experience.",
    "dataset_id": "${DATASET_NAME}"
  },
  {
    "review_id": "rev_005",
    "review_text": "商品の品質は素晴らしいです。配送も迅速で、カスタマーサービスも親切でした。",
    "dataset_id": "${DATASET_NAME}"
  }
]
EOF
    
    # Create analytics queries
    cat > analytics_queries.sql << EOF
-- Overall sentiment distribution
SELECT 
  sentiment_label,
  COUNT(*) as review_count,
  ROUND(AVG(sentiment_score), 3) as avg_sentiment_score,
  ROUND(AVG(sentiment_magnitude), 3) as avg_magnitude
FROM \`${PROJECT_ID}.${DATASET_NAME}.review_analysis\`
GROUP BY sentiment_label
ORDER BY review_count DESC;

-- Language distribution and sentiment by language
SELECT 
  original_language,
  COUNT(*) as review_count,
  ROUND(AVG(sentiment_score), 3) as avg_sentiment,
  COUNTIF(sentiment_label = 'positive') as positive_reviews,
  COUNTIF(sentiment_label = 'negative') as negative_reviews,
  COUNTIF(sentiment_label = 'neutral') as neutral_reviews
FROM \`${PROJECT_ID}.${DATASET_NAME}.review_analysis\`
GROUP BY original_language
ORDER BY review_count DESC;

-- Most mentioned entities across all reviews
SELECT 
  JSON_EXTRACT_SCALAR(entity, '$.name') as entity_name,
  JSON_EXTRACT_SCALAR(entity, '$.type') as entity_type,
  COUNT(*) as mentions,
  ROUND(AVG(CAST(JSON_EXTRACT_SCALAR(entity, '$.salience') AS FLOAT64)), 3) as avg_salience
FROM \`${PROJECT_ID}.${DATASET_NAME}.review_analysis\`,
  UNNEST(JSON_EXTRACT_ARRAY(entities)) as entity
GROUP BY entity_name, entity_type
HAVING mentions > 1
ORDER BY mentions DESC, avg_salience DESC;

-- Recent review trends
SELECT 
  DATE(processing_timestamp) as review_date,
  COUNT(*) as daily_reviews,
  ROUND(AVG(sentiment_score), 3) as daily_avg_sentiment,
  STRING_AGG(DISTINCT original_language) as languages_received
FROM \`${PROJECT_ID}.${DATASET_NAME}.review_analysis\`
GROUP BY review_date
ORDER BY review_date DESC;
EOF
    
    log "Sample data and analytics queries created"
    
    # Test the function with sample data
    info "Testing the deployment with sample reviews..."
    
    # Wait a bit for function to be fully ready
    sleep 10
    
    for review in $(cat sample_reviews.json | jq -c '.[]'); do
        review_id=$(echo "$review" | jq -r '.review_id')
        info "Processing review: $review_id"
        
        response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -d "$review" \
            "${FUNCTION_URL}")
        
        if echo "$response" | jq -e '.status == "success"' > /dev/null; then
            log "Successfully processed review: $review_id"
        else
            warn "Failed to process review $review_id: $response"
        fi
        
        sleep 2  # Brief pause between requests
    done
    
    log "Sample data processing completed"
}

# Function to verify deployment
verify_deployment() {
    info "Verifying deployment..."
    
    # Check function status
    if gcloud functions describe "${FUNCTION_NAME}" \
        --region="${REGION}" \
        --format="value(status)" | grep -q "ACTIVE"; then
        log "Cloud Function is active and ready"
    else
        warn "Cloud Function may not be fully ready"
    fi
    
    # Check BigQuery data
    info "Checking BigQuery data..."
    review_count=$(bq query --use_legacy_sql=false \
        --format=csv \
        --quiet \
        "SELECT COUNT(*) FROM \`${PROJECT_ID}.${DATASET_NAME}.review_analysis\`" | tail -n +2)
    
    if [[ "$review_count" -gt 0 ]]; then
        log "BigQuery contains $review_count processed reviews"
    else
        warn "No reviews found in BigQuery. Check function logs for errors."
    fi
    
    # Display function logs
    info "Recent function logs:"
    gcloud functions logs read "${FUNCTION_NAME}" \
        --region="${REGION}" \
        --limit=10
}

# Function to display completion information
display_completion_info() {
    log "============================================"
    log "Deployment completed successfully!"
    log "============================================"
    log ""
    log "Resources created:"
    log "  - Project: ${PROJECT_ID}"
    log "  - BigQuery Dataset: ${DATASET_NAME}"
    log "  - Cloud Function: ${FUNCTION_NAME}"
    log "  - Function URL: ${FUNCTION_URL}"
    log ""
    log "Sample data and analytics queries are available in:"
    log "  - ${SCRIPT_DIR}/../samples/"
    log ""
    log "To test the function manually:"
    log "  curl -X POST \\"
    log "    -H \"Content-Type: application/json\" \\"
    log "    -d '{\"review_id\":\"test\",\"review_text\":\"This is a test\",\"dataset_id\":\"${DATASET_NAME}\"}' \\"
    log "    \"${FUNCTION_URL}\""
    log ""
    log "To clean up resources, run:"
    log "  ./destroy.sh"
    log ""
    log "Deployment information saved to: ${SCRIPT_DIR}/deployment_info.env"
}

# Main deployment function
main() {
    info "Starting deployment of Smart Product Review Analysis..."
    
    # Initialize log files
    : > "$LOG_FILE"
    : > "$ERROR_LOG"
    
    # Run deployment steps
    check_prerequisites
    setup_environment "$@"
    configure_project
    enable_apis
    create_bigquery_resources
    prepare_function_code
    deploy_function
    create_sample_data
    verify_deployment
    display_completion_info
    
    log "Deployment completed successfully!"
}

# Error handling
trap 'error "Deployment failed at line $LINENO. Check $ERROR_LOG for details."; exit 1' ERR

# Run main function with all arguments
main "$@"