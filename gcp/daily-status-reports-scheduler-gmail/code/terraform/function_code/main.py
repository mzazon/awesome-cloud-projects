"""
Daily System Status Report Generator for Google Cloud Platform

This Cloud Function collects basic system metrics from Cloud Monitoring
and sends formatted email reports via SMTP. The function is designed to
provide automated daily insights about GCP infrastructure health and
resource utilization.

Author: Generated by Terraform for Daily Status Reports Recipe
Version: 1.0
"""

import json
import os
import smtplib
from datetime import datetime, timedelta
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from google.cloud import monitoring_v3
import functions_framework
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Email configuration constants
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587

# Environment variables
SENDER_EMAIL = os.environ.get('SENDER_EMAIL', 'your-email@gmail.com')
SENDER_PASSWORD = os.environ.get('SENDER_PASSWORD', 'your-app-password')
RECIPIENT_EMAIL = os.environ.get('RECIPIENT_EMAIL', 'admin@example.com')
GCP_PROJECT = os.environ.get('GCP_PROJECT', '${project_id}')

@functions_framework.http
def generate_status_report(request):
    """
    HTTP Cloud Function to generate and send daily system status report.
    
    Args:
        request (flask.Request): The request object containing HTTP request data
        
    Returns:
        dict: JSON response with status and message
    """
    try:
        logger.info("Starting daily status report generation")
        
        # Validate environment configuration
        if not validate_configuration():
            return {"status": "error", "message": "Invalid configuration"}, 400
        
        # Initialize monitoring client
        monitoring_client = monitoring_v3.MetricServiceClient()
        project_name = f"projects/{GCP_PROJECT}"
        
        # Collect system metrics
        logger.info(f"Collecting metrics for project: {GCP_PROJECT}")
        report_data = collect_system_metrics(monitoring_client, project_name)
        
        # Format and send email report
        logger.info(f"Sending report to: {RECIPIENT_EMAIL}")
        send_status_email(report_data)
        
        logger.info("Daily status report sent successfully")
        return {
            "status": "success", 
            "message": "Daily status report sent successfully",
            "timestamp": datetime.utcnow().isoformat(),
            "project": GCP_PROJECT
        }
    
    except Exception as e:
        error_msg = f"Error generating status report: {str(e)}"
        logger.error(error_msg)
        return {"status": "error", "message": error_msg}, 500


def validate_configuration():
    """
    Validate that all required environment variables are configured.
    
    Returns:
        bool: True if configuration is valid, False otherwise
    """
    required_vars = {
        'SENDER_EMAIL': SENDER_EMAIL,
        'SENDER_PASSWORD': SENDER_PASSWORD,
        'RECIPIENT_EMAIL': RECIPIENT_EMAIL,
        'GCP_PROJECT': GCP_PROJECT
    }
    
    for var_name, var_value in required_vars.items():
        if not var_value or var_value.startswith('your-'):
            logger.error(f"Environment variable {var_name} is not properly configured")
            return False
    
    return True


def collect_system_metrics(client, project_name):
    """
    Collect key system metrics from Cloud Monitoring.
    
    Args:
        client: Cloud Monitoring client instance
        project_name: Full project name (projects/project-id)
        
    Returns:
        dict: Dictionary containing collected metrics and metadata
    """
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=24)
    
    # Convert to protobuf timestamp format
    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(end_time.timestamp())},
        "start_time": {"seconds": int(start_time.timestamp())}
    })
    
    metrics_data = {
        "timestamp": end_time.strftime("%Y-%m-%d %H:%M:%S UTC"),
        "project_id": GCP_PROJECT,
        "period": "Last 24 hours",
        "collection_status": "success"
    }
    
    try:
        # Collect Compute Engine metrics
        metrics_data["compute_instances"] = collect_compute_metrics(client, project_name, interval)
        
        # Collect Cloud Functions metrics
        metrics_data["cloud_functions"] = collect_function_metrics(client, project_name, interval)
        
        # Collect Storage metrics
        metrics_data["storage_buckets"] = collect_storage_metrics(client, project_name, interval)
        
        # Collect general project health
        metrics_data["project_health"] = collect_project_health_metrics(client, project_name, interval)
        
        logger.info("Successfully collected all system metrics")
        
    except Exception as e:
        logger.warning(f"Partial metrics collection due to error: {e}")
        metrics_data["collection_status"] = f"partial - {str(e)[:100]}"
    
    return metrics_data


def collect_compute_metrics(client, project_name, interval):
    """
    Collect Compute Engine related metrics.
    
    Args:
        client: Cloud Monitoring client
        project_name: Project name
        interval: Time interval for metrics
        
    Returns:
        dict: Compute metrics data
    """
    try:
        # Query compute instance CPU utilization
        request = monitoring_v3.ListTimeSeriesRequest({
            "name": project_name,
            "filter": 'metric.type="compute.googleapis.com/instance/cpu/utilization"',
            "interval": interval,
            "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL
        })
        
        results = list(client.list_time_series(request=request))
        instance_count = len(results)
        
        # Calculate average CPU utilization if instances exist
        avg_cpu = 0
        if results:
            total_cpu = sum([
                point.value.double_value 
                for series in results 
                for point in series.points[:1]  # Latest point only
                if hasattr(point.value, 'double_value')
            ])
            avg_cpu = (total_cpu / len(results)) * 100 if results else 0
        
        return {
            "instance_count": instance_count,
            "average_cpu_utilization": round(avg_cpu, 2),
            "status": "active" if instance_count > 0 else "no_instances"
        }
        
    except Exception as e:
        logger.warning(f"Error collecting compute metrics: {e}")
        return {
            "instance_count": "unavailable",
            "average_cpu_utilization": "unavailable",
            "status": "error"
        }


def collect_function_metrics(client, project_name, interval):
    """
    Collect Cloud Functions related metrics.
    
    Args:
        client: Cloud Monitoring client
        project_name: Project name
        interval: Time interval for metrics
        
    Returns:
        dict: Functions metrics data
    """
    try:
        # Query Cloud Functions executions
        request = monitoring_v3.ListTimeSeriesRequest({
            "name": project_name,
            "filter": 'metric.type="cloudfunctions.googleapis.com/function/executions"',
            "interval": interval,
            "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL
        })
        
        results = list(client.list_time_series(request=request))
        functions_count = len(results)
        
        # Count total executions
        total_executions = 0
        if results:
            total_executions = sum([
                point.value.int64_value 
                for series in results 
                for point in series.points
                if hasattr(point.value, 'int64_value')
            ])
        
        return {
            "function_count": functions_count,
            "total_executions_24h": total_executions,
            "status": "active" if functions_count > 0 else "no_functions"
        }
        
    except Exception as e:
        logger.warning(f"Error collecting function metrics: {e}")
        return {
            "function_count": "unavailable",
            "total_executions_24h": "unavailable",
            "status": "error"
        }


def collect_storage_metrics(client, project_name, interval):
    """
    Collect Cloud Storage related metrics.
    
    Args:
        client: Cloud Monitoring client
        project_name: Project name
        interval: Time interval for metrics
        
    Returns:
        dict: Storage metrics data
    """
    try:
        # Query storage bucket count (approximation via API requests)
        request = monitoring_v3.ListTimeSeriesRequest({
            "name": project_name,
            "filter": 'metric.type="storage.googleapis.com/api/request_count"',
            "interval": interval,
            "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL
        })
        
        results = list(client.list_time_series(request=request))
        api_requests = len(results)
        
        return {
            "api_activity": api_requests,
            "status": "active" if api_requests > 0 else "minimal_activity"
        }
        
    except Exception as e:
        logger.warning(f"Error collecting storage metrics: {e}")
        return {
            "api_activity": "unavailable",
            "status": "error"
        }


def collect_project_health_metrics(client, project_name, interval):
    """
    Collect general project health indicators.
    
    Args:
        client: Cloud Monitoring client
        project_name: Project name
        interval: Time interval for metrics
        
    Returns:
        dict: Project health data
    """
    try:
        # This is a simplified health check
        # In production, you might want to check specific SLIs/SLOs
        
        return {
            "monitoring_api": "operational",
            "data_collection": "successful",
            "report_generation": "operational",
            "overall_status": "healthy"
        }
        
    except Exception as e:
        logger.warning(f"Error collecting project health metrics: {e}")
        return {
            "monitoring_api": "degraded",
            "data_collection": "failed",
            "report_generation": "operational",
            "overall_status": "degraded"
        }


def send_status_email(report_data):
    """
    Send formatted status report via SMTP.
    
    Args:
        report_data (dict): Dictionary containing collected metrics and metadata
        
    Raises:
        Exception: If email sending fails
    """
    try:
        # Create email message
        msg = MimeMultipart()
        msg['From'] = SENDER_EMAIL
        msg['To'] = RECIPIENT_EMAIL
        msg['Subject'] = f"Daily System Status Report - {report_data['timestamp']}"
        
        # Format email body
        body = format_report_body(report_data)
        msg.attach(MimeText(body, 'plain'))
        
        # Send email via SMTP
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
            server.starttls()
            server.login(SENDER_EMAIL, SENDER_PASSWORD)
            server.send_message(msg)
        
        logger.info(f"Status report sent successfully to {RECIPIENT_EMAIL}")
        
    except Exception as e:
        error_msg = f"Error sending email: {e}"
        logger.error(error_msg)
        raise Exception(error_msg)


def format_report_body(data):
    """
    Format system metrics into readable email content.
    
    Args:
        data (dict): Dictionary containing metrics and metadata
        
    Returns:
        str: Formatted email body text
    """
    # Helper function to format metric values
    def format_metric(value):
        return str(value) if value != "unavailable" else "N/A"
    
    compute_info = data.get("compute_instances", {})
    functions_info = data.get("cloud_functions", {})
    storage_info = data.get("storage_buckets", {})
    health_info = data.get("project_health", {})
    
    return f"""
Daily System Status Report
Generated: {data['timestamp']}
Project: {data['project_id']}
Period: {data['period']}
Collection Status: {data.get('collection_status', 'unknown')}

=== INFRASTRUCTURE SUMMARY ===
Compute Instances: {format_metric(compute_info.get('instance_count', 'N/A'))}
  └─ Average CPU Utilization: {format_metric(compute_info.get('average_cpu_utilization', 'N/A'))}%
  └─ Status: {compute_info.get('status', 'unknown')}

Cloud Functions: {format_metric(functions_info.get('function_count', 'N/A'))}
  └─ Executions (24h): {format_metric(functions_info.get('total_executions_24h', 'N/A'))}
  └─ Status: {functions_info.get('status', 'unknown')}

Storage Activity: {format_metric(storage_info.get('api_activity', 'N/A'))} API requests
  └─ Status: {storage_info.get('status', 'unknown')}

=== SYSTEM HEALTH ===
✅ Monitoring API: {health_info.get('monitoring_api', 'unknown')}
✅ Data Collection: {health_info.get('data_collection', 'unknown')}
✅ Report Generation: {health_info.get('report_generation', 'unknown')}
🔍 Overall Status: {health_info.get('overall_status', 'unknown')}

=== QUICK ACCESS LINKS ===
• Cloud Console: https://console.cloud.google.com/home/dashboard?project={data['project_id']}
• Monitoring: https://console.cloud.google.com/monitoring?project={data['project_id']}
• Cloud Functions: https://console.cloud.google.com/functions/list?project={data['project_id']}
• Cloud Scheduler: https://console.cloud.google.com/cloudscheduler?project={data['project_id']}

=== RECOMMENDATIONS ===
• Review resource utilization trends in Cloud Monitoring
• Check for any active alerts or incidents in the console
• Verify backup and disaster recovery processes are functioning
• Consider setting up alerting policies for proactive monitoring

=== NEXT STEPS ===
• Monitor trends over time to identify patterns
• Set up custom dashboards for key metrics
• Configure alerting for critical thresholds
• Review and optimize resource usage for cost efficiency

---
Generated by Cloud Functions Daily Status Reporter
Project: {data['project_id']}
Timestamp: {data['timestamp']}
Terraform Recipe: daily-status-reports-scheduler-gmail

This is an automated report. For detailed metrics and analysis, visit the
Google Cloud Console monitoring section.
"""


if __name__ == "__main__":
    # For local testing - this won't run in Cloud Functions
    print("Daily Status Report Generator")
    print("This function is designed to run in Google Cloud Functions")
    print("Use 'functions-framework --target=generate_status_report' for local testing")