# Infrastructure Manager Configuration for JSON Validator API with Cloud Functions
# This configuration deploys a serverless JSON validation and formatting API using 
# Google Cloud Functions integrated with Cloud Storage for handling large JSON files.
#
# Recipe: JSON Validator API with Cloud Functions
# Services: Cloud Functions, Cloud Storage
# Estimated deployment time: 5-10 minutes

# Required APIs and Provider Configuration
terraform:
  required_providers:
    google:
      source: hashicorp/google
      version: "~> 5.0"
    archive:
      source: hashicorp/archive
      version: "~> 2.4"
    random:
      source: hashicorp/random
      version: "~> 3.6"

# Input Variables for Customization
variables:
  # Core project configuration
  project_id:
    description: "Google Cloud Project ID where resources will be deployed"
    type: string
    validation:
      condition: length(var.project_id) > 0
      error_message: "Project ID must not be empty."

  region:
    description: "Google Cloud region for deploying resources"
    type: string
    default: "us-central1"
    validation:
      condition: contains([
        "us-central1", "us-west1", "us-west2", "us-west3", "us-west4",
        "us-east1", "us-east4", "europe-west1", "europe-west2", 
        "europe-west3", "asia-east1", "asia-northeast1", "asia-southeast1"
      ], var.region)
      error_message: "Region must be a valid Google Cloud region."

  # Naming and resource configuration
  function_name:
    description: "Name for the Cloud Function (will be prefixed with json-validator-)"
    type: string
    default: "api"
    validation:
      condition: can(regex("^[a-z]([a-z0-9-]*[a-z0-9])?$", var.function_name))
      error_message: "Function name must contain only lowercase letters, numbers, and hyphens."

  bucket_name_suffix:
    description: "Suffix for the Cloud Storage bucket name (auto-generated if empty)"
    type: string
    default: ""

  # Function configuration
  function_memory:
    description: "Memory allocation for the Cloud Function in MB"
    type: number
    default: 256
    validation:
      condition: contains([128, 256, 512, 1024, 2048, 4096, 8192], var.function_memory)
      error_message: "Function memory must be one of: 128, 256, 512, 1024, 2048, 4096, 8192."

  function_timeout:
    description: "Timeout for the Cloud Function in seconds"
    type: number
    default: 60
    validation:
      condition: var.function_timeout >= 1 && var.function_timeout <= 540
      error_message: "Function timeout must be between 1 and 540 seconds."

  max_instances:
    description: "Maximum number of function instances"
    type: number
    default: 10
    validation:
      condition: var.max_instances >= 1 && var.max_instances <= 3000
      error_message: "Max instances must be between 1 and 3000."

  # Storage configuration
  storage_class:
    description: "Storage class for the Cloud Storage bucket"
    type: string
    default: "STANDARD"
    validation:
      condition: contains(["STANDARD", "NEARLINE", "COLDLINE", "ARCHIVE"], var.storage_class)
      error_message: "Storage class must be one of: STANDARD, NEARLINE, COLDLINE, ARCHIVE."

  enable_versioning:
    description: "Enable versioning on the Cloud Storage bucket"
    type: bool
    default: true

  # Security and access configuration
  allow_unauthenticated:
    description: "Allow unauthenticated access to the Cloud Function"
    type: bool
    default: true

  # Tagging and metadata
  labels:
    description: "Labels to apply to all resources"
    type: map(string)
    default: {
      purpose = "json-validation"
      recipe = "json-validator-api-functions-storage"
      managed-by = "infrastructure-manager"
    }

# Generate random suffix for unique resource names
resource "random_id" "suffix":
  byte_length: 4

# Local values for computed names and configurations
locals:
  # Generate unique resource names
  function_name = "json-validator-${var.function_name}-${random_id.suffix.hex}"
  bucket_name = var.bucket_name_suffix != "" ? 
    "json-files-${var.project_id}-${var.bucket_name_suffix}" : 
    "json-files-${var.project_id}-${random_id.suffix.hex}"

  # Function source code directory
  function_source_dir = "${path.module}/function-source"
  
  # Common labels for all resources
  common_labels = merge(var.labels, {
    deployment-timestamp = formatdate("YYYY-MM-DD-hhmm", timestamp())
  })

  # Function environment variables
  function_env_vars = {
    PROJECT_ID = var.project_id
    BUCKET_NAME = local.bucket_name
    FUNCTION_REGION = var.region
  }
}

# Enable required Google Cloud APIs
resource "google_project_service" "required_apis":
  for_each = toset([
    "cloudfunctions.googleapis.com",
    "cloudbuild.googleapis.com",
    "storage.googleapis.com",
    "logging.googleapis.com",
    "monitoring.googleapis.com"
  ])

  project = var.project_id
  service = each.value
  
  # Prevent disabling these APIs on resource destruction
  disable_on_destroy = false
  
  # Wait for API enablement before proceeding
  timeouts {
    create = "10m"
  }
}

# Cloud Storage bucket for JSON file processing
resource "google_storage_bucket" "json_files":
  name          = local.bucket_name
  project       = var.project_id
  location      = var.region
  storage_class = var.storage_class
  
  # Enable uniform bucket-level access for better security
  uniform_bucket_level_access = true
  
  # Configure versioning based on input variable
  versioning {
    enabled = var.enable_versioning
  }
  
  # Lifecycle management to optimize costs
  lifecycle_rule {
    condition {
      age = 30
    }
    action {
      type = "Delete"
    }
  }
  
  # CORS configuration for web application access
  cors {
    origin          = ["*"]
    method          = ["GET", "HEAD", "PUT", "POST", "DELETE"]
    response_header = ["*"]
    max_age_seconds = 3600
  }
  
  # Apply labels for resource management
  labels = local.common_labels
  
  # Prevent accidental deletion
  lifecycle {
    prevent_destroy = false
  }
  
  depends_on = [google_project_service.required_apis]
}

# Create IAM binding for public read access to bucket objects (if needed for public API)
resource "google_storage_bucket_iam_member" "public_read":
  count = var.allow_unauthenticated ? 1 : 0
  
  bucket = google_storage_bucket.json_files.name
  role   = "roles/storage.objectViewer"
  member = "allUsers"
  
  depends_on = [google_storage_bucket.json_files]
}

# Create function source code files
resource "local_file" "function_main":
  filename = "${local.function_source_dir}/main.py"
  content = <<-EOT
import json
import logging
from flask import Request, jsonify
from google.cloud import storage
from google.cloud import logging as cloud_logging
import functions_framework
import traceback
from typing import Dict, Any, Union
import os

# Configure logging
cloud_logging.Client().setup_logging()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Cloud Storage client
storage_client = storage.Client()

# Get environment variables
PROJECT_ID = os.environ.get('PROJECT_ID', '')
BUCKET_NAME = os.environ.get('BUCKET_NAME', '')

def validate_json_content(content: str) -> Dict[str, Any]:
    """
    Validate and format JSON content.
    
    Args:
        content: String containing JSON data
        
    Returns:
        Dictionary with validation results
    """
    try:
        # Parse JSON to validate syntax
        parsed_json = json.loads(content)
        
        # Format with proper indentation
        formatted_json = json.dumps(parsed_json, indent=2, sort_keys=True)
        
        # Calculate basic statistics
        stats = {
            'size_bytes': len(content),
            'formatted_size_bytes': len(formatted_json),
            'keys_count': len(parsed_json) if isinstance(parsed_json, dict) else 0,
            'type': type(parsed_json).__name__
        }
        
        return {
            'valid': True,
            'formatted_json': formatted_json,
            'original_json': parsed_json,
            'statistics': stats,
            'message': 'JSON is valid and properly formatted'
        }
        
    except json.JSONDecodeError as e:
        return {
            'valid': False,
            'error': str(e),
            'error_type': 'JSONDecodeError',
            'line': getattr(e, 'lineno', None),
            'column': getattr(e, 'colno', None),
            'message': f'Invalid JSON syntax: {str(e)}'
        }
    except Exception as e:
        logger.error(f"Unexpected error during JSON validation: {str(e)}")
        return {
            'valid': False,
            'error': str(e),
            'error_type': type(e).__name__,
            'message': 'Unexpected error occurred during validation'
        }

def process_storage_file(bucket_name: str, file_name: str) -> Dict[str, Any]:
    """
    Process JSON file from Cloud Storage.
    
    Args:
        bucket_name: Name of the storage bucket
        file_name: Name of the file to process
        
    Returns:
        Dictionary with validation results
    """
    try:
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_name)
        
        if not blob.exists():
            return {
                'valid': False,
                'error': f'File {file_name} not found in bucket {bucket_name}',
                'message': 'File not found in storage'
            }
        
        # Download and validate the file content
        content = blob.download_as_text()
        result = validate_json_content(content)
        
        # Add storage metadata
        result['storage_info'] = {
            'bucket': bucket_name,
            'file': file_name,
            'size': blob.size,
            'content_type': blob.content_type,
            'updated': blob.updated.isoformat() if blob.updated else None
        }
        
        return result
        
    except Exception as e:
        logger.error(f"Error processing storage file: {str(e)}")
        return {
            'valid': False,
            'error': str(e),
            'message': 'Error accessing or processing storage file'
        }

@functions_framework.http
def json_validator_api(request: Request) -> Union[str, tuple]:
    """
    HTTP Cloud Function for JSON validation and formatting.
    
    Accepts JSON data via POST request body or processes files from Cloud Storage
    via query parameters.
    """
    try:
        # Set CORS headers for web applications
        headers = {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type',
            'Content-Type': 'application/json'
        }
        
        # Handle preflight OPTIONS request
        if request.method == 'OPTIONS':
            return ('', 200, headers)
        
        # Handle GET request for health check
        if request.method == 'GET':
            # Check for storage file processing parameters
            bucket_name = request.args.get('bucket')
            file_name = request.args.get('file')
            
            if bucket_name and file_name:
                logger.info(f"Processing file {file_name} from bucket {bucket_name}")
                result = process_storage_file(bucket_name, file_name)
                return jsonify(result), 200, headers
            
            # Default health check response
            return jsonify({
                'status': 'healthy',
                'service': 'JSON Validator API',
                'version': '1.1',
                'project_id': PROJECT_ID,
                'storage_bucket': BUCKET_NAME,
                'endpoints': {
                    'POST /': 'Validate JSON in request body',
                    'GET /?bucket=BUCKET&file=FILE': 'Validate JSON file from storage'
                }
            }), 200, headers
        
        # Handle POST request with JSON in body
        if request.method == 'POST':
            if not request.data:
                return jsonify({
                    'valid': False,
                    'error': 'No data provided',
                    'message': 'Please provide JSON data in the request body'
                }), 400, headers
            
            # Get content as string for validation
            content = request.get_data(as_text=True)
            logger.info(f"Validating JSON content, size: {len(content)} bytes")
            
            result = validate_json_content(content)
            
            # Return appropriate HTTP status code
            status_code = 200 if result['valid'] else 400
            return jsonify(result), status_code, headers
        
        # Method not allowed
        return jsonify({
            'valid': False,
            'error': 'Method not allowed',
            'message': 'Only GET and POST methods are supported'
        }), 405, headers
        
    except Exception as e:
        logger.error(f"Unexpected error in function: {str(e)}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'valid': False,
            'error': str(e),
            'message': 'Internal server error occurred'
        }), 500, {'Content-Type': 'application/json'}
EOT

  depends_on = [google_project_service.required_apis]
}

# Create requirements.txt for function dependencies
resource "local_file" "function_requirements":
  filename = "${local.function_source_dir}/requirements.txt"
  content = <<-EOT
functions-framework==3.8.1
google-cloud-storage==2.18.0
google-cloud-logging==3.11.2
EOT

  depends_on = [local_file.function_main]
}

# Create archive of function source code
data "archive_file" "function_source":
  type        = "zip"
  source_dir  = local.function_source_dir
  output_path = "${path.module}/function-source.zip"
  excludes    = ["__pycache__", "*.pyc", ".git"]
  
  depends_on = [
    local_file.function_main,
    local_file.function_requirements
  ]
}

# Cloud Storage bucket for function source code
resource "google_storage_bucket" "function_source":
  name     = "${local.bucket_name}-function-source"
  project  = var.project_id
  location = var.region
  
  # Use NEARLINE storage class for infrequently accessed function source
  storage_class = "NEARLINE"
  
  # Enable uniform bucket-level access
  uniform_bucket_level_access = true
  
  # Apply labels
  labels = merge(local.common_labels, {
    purpose = "function-source"
  })
  
  depends_on = [google_project_service.required_apis]
}

# Upload function source code to Cloud Storage
resource "google_storage_bucket_object" "function_source":
  name   = "function-source-${data.archive_file.function_source.output_md5}.zip"
  bucket = google_storage_bucket.function_source.name
  source = data.archive_file.function_source.output_path
}

# Service account for Cloud Function (following least privilege principle)
resource "google_service_account" "function_sa":
  account_id   = "json-validator-function-sa"
  display_name = "JSON Validator Function Service Account"
  description  = "Service account for JSON Validator Cloud Function with minimal required permissions"
  project      = var.project_id
  
  depends_on = [google_project_service.required_apis]
}

# Grant necessary permissions to function service account
resource "google_project_iam_member" "function_storage_access":
  project = var.project_id
  role    = "roles/storage.objectViewer"
  member  = "serviceAccount:${google_service_account.function_sa.email}"
  
  depends_on = [google_service_account.function_sa]
}

resource "google_project_iam_member" "function_logging":
  project = var.project_id
  role    = "roles/logging.logWriter"
  member  = "serviceAccount:${google_service_account.function_sa.email}"
  
  depends_on = [google_service_account.function_sa]
}

# Deploy the Cloud Function
resource "google_cloudfunctions_function" "json_validator":
  name        = local.function_name
  project     = var.project_id
  region      = var.region
  description = "Serverless JSON validation and formatting API with Cloud Storage integration"
  
  # Function runtime configuration
  runtime               = "python311"
  available_memory_mb   = var.function_memory
  timeout              = var.function_timeout
  max_instances        = var.max_instances
  min_instances        = 0
  entry_point          = "json_validator_api"
  
  # Function source code configuration
  source_archive_bucket = google_storage_bucket.function_source.name
  source_archive_object = google_storage_bucket_object.function_source.name
  
  # HTTP trigger configuration
  trigger {
    http_trigger {
      url = null
    }
  }
  
  # Environment variables
  environment_variables = local.function_env_vars
  
  # Service account configuration
  service_account_email = google_service_account.function_sa.email
  
  # Network and security settings
  ingress_settings = "ALLOW_ALL"
  
  # Apply labels for resource management
  labels = local.common_labels
  
  depends_on = [
    google_storage_bucket_object.function_source,
    google_service_account.function_sa,
    google_project_iam_member.function_storage_access,
    google_project_iam_member.function_logging
  ]
}

# IAM policy to allow unauthenticated access (if enabled)
resource "google_cloudfunctions_function_iam_member" "public_access":
  count = var.allow_unauthenticated ? 1 : 0
  
  project        = var.project_id
  region         = var.region
  cloud_function = google_cloudfunctions_function.json_validator.name
  role           = "roles/cloudfunctions.invoker"
  member         = "allUsers"
  
  depends_on = [google_cloudfunctions_function.json_validator]
}

# Create sample JSON files for testing
resource "google_storage_bucket_object" "sample_valid_json":
  name    = "samples/valid-sample.json"
  bucket  = google_storage_bucket.json_files.name
  content = jsonencode({
    users = [
      {
        id = 1
        name = "John Doe"
        email = "john@example.com"
        active = true
        roles = ["admin", "user"]
      },
      {
        id = 2
        name = "Jane Smith"
        email = "jane@example.com"
        active = false
        roles = ["user"]
      }
    ]
    metadata = {
      total = 2
      created = "2025-01-15T10:00:00Z"
    }
  })
  
  content_type = "application/json"
  
  depends_on = [google_storage_bucket.json_files]
}

resource "google_storage_bucket_object" "sample_invalid_json":
  name    = "samples/invalid-sample.json"
  bucket  = google_storage_bucket.json_files.name
  # This creates an intentionally malformed JSON for testing
  content = <<-EOT
{
  "users": [
    {
      "id": 1,
      "name": "John Doe",
      "email": "john@example.com",
      "active": true,
      "roles": ["admin", "user"]
    },
    {
      "id": 2,
      "name": "Jane Smith",
      "email": "jane@example.com",
      "active": false,
      "roles": ["user"]
    }
  ],
  "metadata": {
    "total": 2,
    "created": "2025-01-15T10:00:00Z"
  }
  // Missing closing brace and invalid comment syntax
EOT
  
  content_type = "application/json"
  
  depends_on = [google_storage_bucket.json_files]
}

# Output values for verification and integration
outputs:
  # Function information
  function_name:
    description = "Name of the deployed Cloud Function"
    value = google_cloudfunctions_function.json_validator.name

  function_url:
    description = "HTTPS URL for the deployed Cloud Function"
    value = google_cloudfunctions_function.json_validator.https_trigger_url

  function_region:
    description = "Region where the Cloud Function is deployed"
    value = google_cloudfunctions_function.json_validator.region

  # Storage information
  storage_bucket_name:
    description = "Name of the Cloud Storage bucket for JSON files"
    value = google_storage_bucket.json_files.name

  storage_bucket_url:
    description = "URL of the Cloud Storage bucket"
    value = google_storage_bucket.json_files.url

  # Service account information
  function_service_account:
    description = "Email of the service account used by the Cloud Function"
    value = google_service_account.function_sa.email

  # Testing information
  test_commands:
    description = "Sample commands for testing the deployed function"
    value = {
      health_check = "curl -X GET '${google_cloudfunctions_function.json_validator.https_trigger_url}'"
      validate_json = "curl -X POST '${google_cloudfunctions_function.json_validator.https_trigger_url}' -H 'Content-Type: application/json' -d '{\"test\": \"data\"}'"
      validate_storage_file = "curl -X GET '${google_cloudfunctions_function.json_validator.https_trigger_url}?bucket=${google_storage_bucket.json_files.name}&file=samples/valid-sample.json'"
    }

  # Resource identifiers for management
  resource_ids:
    description = "Resource identifiers for management and monitoring"
    value = {
      project_id = var.project_id
      region = var.region
      function_name = google_cloudfunctions_function.json_validator.name
      bucket_name = google_storage_bucket.json_files.name
      service_account_email = google_service_account.function_sa.email
    }

  # Cost and usage information
  estimated_costs:
    description = "Estimated monthly costs for light usage (informational only)"
    value = {
      function_invocations_free_tier = "2,000,000 requests/month"
      storage_free_tier = "5 GB/month"
      estimated_monthly_cost = "$0.00 - $0.50 for development/testing workloads"
      note = "Actual costs depend on usage patterns and may vary"
    }